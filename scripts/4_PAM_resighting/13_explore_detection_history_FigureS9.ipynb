{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore reviewed detection history\n",
    "Plot maps of number of individuals detected per point for each site and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "def figsize(w,h):\n",
    "    plt.rcParams['figure.figsize']=[w,h]\n",
    "figsize(15,5) #for big visuals\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the publicly available PAM dataset. Put the path to the folder here:\n",
    "dataset_dir = \"../../../pam_dataset_v4/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dethist = (\n",
    "    pd.read_csv(\n",
    "        f\"{dataset_dir}/detection_history_complete.csv\",\n",
    "        index_col=0,\n",
    "    )\n",
    "    .drop(columns=[\"notes\", \"reviewer\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "dethist.fillna(0, inplace=True)\n",
    "dethist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(4, 1)\n",
    "for year, yeardf in dethist.groupby(\"year\"):\n",
    "    counts, n = np.histogram(\n",
    "        yeardf.drop(columns=\"year\").set_index([\"cluster_reviewed\"]).sum(1),\n",
    "        bins=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "    )\n",
    "    n = n[:-1]\n",
    "    plt.plot(\n",
    "        n[1:],\n",
    "        counts[1:],\n",
    "        label=year,\n",
    "        alpha=0.5,\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    plt.xticks(\n",
    "        n[1:],\n",
    "    )\n",
    "plt.title(\"number of days individual is detected in 12-day detection history\")\n",
    "\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cluster_samples = pd.read_csv(\n",
    "    f\"{dataset_dir}/all_clips_with_cleaned_clusters.csv\",\n",
    "    parse_dates=[\"datetime\", \"date\", \"time\"],\n",
    ")\n",
    "all_cluster_samples[\"features3d\"] = all_cluster_samples[\"features3d\"].apply(eval)\n",
    "all_cluster_samples[\"time\"] = all_cluster_samples[\"time\"].apply(lambda x: x.time())\n",
    "all_cluster_samples[\"date\"] = all_cluster_samples[\"date\"].apply(lambda x: x.date())\n",
    "all_cluster_samples[\"year\"] = all_cluster_samples[\"date\"].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cluster_samples.groupby(\"year\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cluster_samples[\"date1\"] = all_cluster_samples[\"date\"].apply(\n",
    "    lambda x: x.replace(year=2000)\n",
    ")\n",
    "all_cluster_samples[\"year\"] = all_cluster_samples.date.apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for a given point, visualize each individual's activity over the course of a season, for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize 10 points\n",
    "n_individuals_per_point = all_cluster_samples.groupby([\"point_code\"])[\n",
    "    \"cluster_reviewed\"\n",
    "].nunique()\n",
    "diverse_points = n_individuals_per_point[n_individuals_per_point > 3].index\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "viz = all_cluster_samples[\n",
    "    all_cluster_samples[\"point_code\"].apply(lambda x: x in diverse_points)\n",
    "]\n",
    "# # Create the FacetGrid, ensuring data is divided by the 'year' column\n",
    "g = sns.FacetGrid(data=viz, col=\"year\", row=\"point_code\", sharey=True, sharex=False)\n",
    "\n",
    "# Map the `sns.histplot` to each subset of data\n",
    "g.map_dataframe(sns.histplot, x=\"date\", hue=\"cluster_reviewed\", multiple=\"stack\")\n",
    "\n",
    "# Adjust the layout for clarity\n",
    "g.set_axis_labels(\"Date\", \"Count\")\n",
    "g.set_titles(\"Year: {col_name}\")\n",
    "g.tight_layout()\n",
    "\n",
    "# plt.savefig('../../figures/per_point_activity_across_dates.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cluster_samples.groupby([\"year\", \"site\"])[\"cluster_reviewed\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cluster_samples.groupby([\"year\", \"site\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cluster_samples[\"date1\"] = all_cluster_samples[\"date\"].apply(\n",
    "    lambda x: x.replace(year=2000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load table of location and habitat variables\n",
    "points = pd.read_csv(\n",
    "    f\"{dataset_dir}/habitat_measures_at_points.csv\",\n",
    "    index_col=\"point_code\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add coordinates to detection df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_cluster_samples[\"utm_E\"] = all_cluster_samples.point_code.map(points[\"utm_E\"])\n",
    "# all_cluster_samples[\"utm_N\"] = all_cluster_samples.point_code.map(points[\"utm_N\"])\n",
    "# all_cluster_samples[\"utm_zone\"] = all_cluster_samples.point_code.map(\n",
    "#     points[\"utm_zone\"]\n",
    "# ).astype(int)\n",
    "# all_cluster_samples[\"utm_letter\"] = all_cluster_samples.point_code.map(\n",
    "#     points[\"utm_letter\"]\n",
    "# )\n",
    "# all_cluster_samples[\"lon\"] = all_cluster_samples.point_code.map(points[\"longitude\"])\n",
    "# all_cluster_samples[\"lat\"] = all_cluster_samples.point_code.map(points[\"latitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map of N individuals per point for each site and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_hist = (\n",
    "    pd.read_csv(\n",
    "        f\"{dataset_dir}/detection_history_complete.csv\",\n",
    "        index_col=0,\n",
    "    )\n",
    "    .drop(columns=[\"notes\", \"reviewer\"])\n",
    "    .reset_index(drop=True)\n",
    "    .set_index(\"cluster_reviewed\")\n",
    "    .fillna(0)\n",
    ")\n",
    "det_hist[\"point_code\"] = det_hist.index.to_series().apply(lambda x: x.split(\"_\")[0])\n",
    "det_hist[\"lon\"] = det_hist.point_code.map(points[\"longitude\"])\n",
    "det_hist[\"lat\"] = det_hist.point_code.map(points[\"latitude\"])\n",
    "det_hist[\"site\"] = det_hist.point_code.map(points[\"site\"])\n",
    "date_cols = det_hist.columns[1:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_hist[\"detected\"] = det_hist[date_cols].sum(axis=1) > 0\n",
    "n_per_year = (\n",
    "    det_hist[det_hist[\"detected\"]]\n",
    "    .reset_index()\n",
    "    .groupby([\"point_code\", \"year\"])[\"cluster_reviewed\"]\n",
    "    .nunique()\n",
    ")\n",
    "n_per_year = n_per_year.unstack().fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_per_year[\"longitude\"] = (\n",
    "    n_per_year.reset_index()[\"point_code\"].map(points[\"longitude\"]).values\n",
    ")\n",
    "n_per_year[\"latitude\"] = (\n",
    "    n_per_year.reset_index()[\"point_code\"].map(points[\"latitude\"]).values\n",
    ")\n",
    "n_per_year[\"site\"] = n_per_year.reset_index()[\"point_code\"].map(points[\"site\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "\n",
    "# Sample structure of n_per_year\n",
    "# n_per_year = pd.read_csv(\"your_data.csv\", index_col=\"point_code\")\n",
    "\n",
    "# Years (assume all except lon, lat, site are years)\n",
    "# year_cols = [col for col in n_per_year.columns if col not in [\"longitude\", \"latitude\", \"site\"]]\n",
    "sites = n_per_year[\"site\"].unique()\n",
    "\n",
    "# Convert to GeoDataFrame in Web Mercator\n",
    "gdf_total = gpd.GeoDataFrame(\n",
    "    n_per_year,\n",
    "    geometry=gpd.points_from_xy(n_per_year.longitude, n_per_year.latitude),\n",
    "    crs=\"EPSG:4326\",\n",
    ").to_crs(epsg=3857)\n",
    "\n",
    "gdf_points = gpd.GeoDataFrame(\n",
    "    points,\n",
    "    geometry=gpd.points_from_xy(points.longitude, points.latitude),\n",
    "    crs=\"EPSG:4326\",\n",
    ").to_crs(epsg=3857)\n",
    "# gdf_singletons = gpd.GeoDataFrame(\n",
    "#     n_singletons_per_year,\n",
    "#     geometry=gpd.points_from_xy(n_singletons_per_year.lon, n_singletons_per_year.lat),\n",
    "#     crs='EPSG:4326'\n",
    "# ).to_crs(epsg=3857)\n",
    "\n",
    "# Plot setup\n",
    "year_cols = [2021, 2022, 2023, 2024]\n",
    "\n",
    "n_rows = len(year_cols)\n",
    "n_cols = len(sites)\n",
    "fig, axes = plt.subplots(\n",
    "    n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows), squeeze=False\n",
    ")\n",
    "\n",
    "for i, year in enumerate(year_cols):\n",
    "    for j, site in enumerate(sites):\n",
    "        ax = axes[i][j]\n",
    "        # all points\n",
    "        gdf_points[gdf_points.site == site].plot(\n",
    "            ax=ax,\n",
    "            markersize=1,\n",
    "            alpha=1,\n",
    "            facecolor=\"black\",\n",
    "            label=\"ARUs\",\n",
    "        )\n",
    "\n",
    "        # Total counts\n",
    "        total_subset = gdf_total[gdf_total[\"site\"] == site].copy()\n",
    "        total_subset[\"size\"] = total_subset[year].fillna(0) * 20\n",
    "        total_subset.plot(\n",
    "            ax=ax,\n",
    "            markersize=total_subset[\"size\"],\n",
    "            alpha=1,\n",
    "            edgecolor=\"k\",\n",
    "            facecolor=\"blue\",\n",
    "            label=\"Total\",\n",
    "        )\n",
    "\n",
    "        # Basemap and labels\n",
    "        ctx.add_basemap(ax, source=ctx.providers.USGS.USTopo)\n",
    "        ax.set_title(f\"{site} - {year}\")\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        from matplotlib.lines import Line2D\n",
    "\n",
    "        # Only add legend to first subplot\n",
    "        if i == 0 and j == 0:\n",
    "            legend_elements = [\n",
    "                Line2D(\n",
    "                    [0],\n",
    "                    [0],\n",
    "                    marker=\"o\",\n",
    "                    color=\"w\",\n",
    "                    label=\"individuals detected\",\n",
    "                    markerfacecolor=\"blue\",\n",
    "                    markersize=10,\n",
    "                    markeredgecolor=\"k\",\n",
    "                ),\n",
    "                Line2D(\n",
    "                    [0],\n",
    "                    [0],\n",
    "                    marker=\"o\",\n",
    "                    color=\"black\",\n",
    "                    label=\"ARU without OVEN\",\n",
    "                    markerfacecolor=\"black\",\n",
    "                    markersize=1,\n",
    "                    markeredgecolor=\"black\",\n",
    "                ),\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc=\"upper right\")\n",
    "\n",
    "\n",
    "legend_values = [1, 3, 5]  # These should correspond to your raw values\n",
    "legend_sizes = np.array(legend_values) * 20  # Same scale as used above\n",
    "\n",
    "legend_handles = [\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"o\",\n",
    "        color=\"w\",\n",
    "        label=str(v),\n",
    "        markerfacecolor=\"blue\",\n",
    "        markeredgecolor=\"k\",\n",
    "        markersize=np.sqrt(s),\n",
    "    )  # Matplotlib uses sqrt(size)\n",
    "    for v, s in zip(legend_values, legend_sizes)\n",
    "]\n",
    "\n",
    "# Add to plot\n",
    "ax.legend(\n",
    "    handles=legend_handles,\n",
    "    title=\"individuals detected\",\n",
    "    loc=\"upper right\",\n",
    "    frameon=True,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.legend()\n",
    "plt.savefig(\"../../figures/FigureS9_maps_of_abundance_per_site_year.pdf\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opso0110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
