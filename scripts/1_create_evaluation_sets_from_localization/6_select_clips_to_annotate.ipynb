{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each localization grid, randomly select Ovenbird localized singing events to manually review\n",
    "\n",
    "> Note: the full audio data used by this script is not provided in this repository, the script is provided for reference only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "np.random.seed(2024)\n",
    "random.seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_events_dir = \"REDACTED\"  # matches out_dir of 5_remove_duplicate_events.py\n",
    "splits_path = \"REDACTED\"  # location to save val/test set csvs, matches splits_path of 7_annotate_localized_songs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array\n",
       "SBT-3-51    12084\n",
       "SBT-3-7     10004\n",
       "SBT-3-49     9786\n",
       "SBT-6-76     7565\n",
       "SBT-6-79     6860\n",
       "SBT-3-9      4116\n",
       "SBT-3-15     3066\n",
       "SBT-3-33     2726\n",
       "SBT-3-32     1887\n",
       "SBT-3-18     1378\n",
       "SBT-6-81      813\n",
       "SBT-3-39      507\n",
       "SBT-6-83      169\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count localized events\n",
    "random.seed(2024)\n",
    "\n",
    "clip_dfs = pd.concat([pd.read_csv(p) for p in glob(f\"{filtered_events_dir}/*.csv\")])\n",
    "clip_dfs.array.value_counts().to_csv(\"n_localized_events_per_array.csv\")\n",
    "print(len(clip_dfs))\n",
    "clip_dfs.array.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2024)\n",
    "\n",
    "clip_dfs = pd.concat(\n",
    "    [pd.read_csv(p) for p in glob(f\"{filtered_events_dir}/*.csv\")]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "\n",
    "# split into train, val, and test\n",
    "# SBT-6-83 only has a handful of Ovenbird detections; 3-7 has no clear territories from localization; 6-76 has 3 clear territories;\n",
    "test_df = clip_dfs[\n",
    "    clip_dfs.array.apply(lambda x: x in (\"SBT-6-83\", \"SBT-3-7\", \"SBT-6-76\"))\n",
    "]\n",
    "trainval = clip_dfs.drop(test_df.index).reset_index(drop=True)\n",
    "test_df = test_df.reset_index()\n",
    "# test_df.to_csv(f\"{splits_path}/test_unlabeled.csv\", index=False)\n",
    "\n",
    "# select 100 events from each array, annotate closest, then apply label to all clips from the array\n",
    "N_events_to_annotate_test = 100\n",
    "events_to_annotate = []\n",
    "for array, df_subset in test_df.groupby(\"array\"):\n",
    "    event_ids = sorted(df_subset.event_id.unique())\n",
    "    if len(event_ids) > N_events_to_annotate_test:\n",
    "        event_ids = random.sample(event_ids, N_events_to_annotate_test)\n",
    "    events_to_annotate.extend(event_ids)\n",
    "\n",
    "test_to_annnotate = test_df[test_df.event_id.apply(lambda x: x in events_to_annotate)]\n",
    "\n",
    "test_to_annnotate.to_csv(f\"{splits_path}/test_to_annotate.csv\", index=False)\n",
    "# only annotate the closest clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7200, 500, 3228, 233]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from the validaton and test set data, select stratified random subset of _events_ to annotate\n",
    "# always annotate the nearest clip;\n",
    "# then assign labels to other clips from the same event\n",
    "# these will form the validation set\n",
    "random.seed(2024)\n",
    "\n",
    "N_events_to_annotate = 50\n",
    "events_to_annotate = []\n",
    "for array, df_subset in trainval.groupby(\"array\"):\n",
    "    event_ids = df_subset.event_id.unique()\n",
    "    if len(event_ids) > N_events_to_annotate:\n",
    "        event_ids = random.sample(sorted(event_ids), N_events_to_annotate)\n",
    "    events_to_annotate.extend(event_ids)\n",
    "\n",
    "val_df = trainval[trainval.event_id.apply(lambda x: x in events_to_annotate)]\n",
    "train_df = trainval.drop(val_df.index)\n",
    "\n",
    "[len(df.event_id.unique()) for df in (train_df, val_df, test_df, test_to_annnotate)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df.to_csv(f\"{splits_path}/test_set_to_anotate.csv\", index=False)\n",
    "# train_df.to_csv(f\"{splits_path}/validation_set_to_annotate_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next:\n",
    "1. annotate individual identities for the closest clip in each event for val_df and test_df_to_annotate\n",
    "2. apply ID labels to other clips from the same event\n",
    "3. compare labels to spatial positions\n",
    "4. use as evaluation for AIID feature extractors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opso0110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
