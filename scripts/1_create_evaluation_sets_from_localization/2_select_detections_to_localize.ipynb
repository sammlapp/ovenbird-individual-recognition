{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select hawkears detections to localize\n",
    "\n",
    "summarize detections of all species in HawkEars into a 0/1 table with a set of species of interest\n",
    "\n",
    "use a threshold of -1.0 (logit score) for all species\n",
    "\n",
    "save sparse dataframes for space and memory efficiency\n",
    "\n",
    "Note: the complete set of HawkEars scores used by this script is not provided in this repository, the script is provided for reference only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregate detections and store as sparse dataframe\n",
    "let's do just one deployment to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize']=[12,8] #for big visuals\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# paths\n",
    "score_files_dir = \"REDACTED\" # matches out_dir of 1_detect_species_HawkEars.py\n",
    "save_dir = \"REDACTED\" # matches \n",
    "audio_dir = \"REDACTED\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpl = \"SBT-6-76\"\n",
    "score_files = glob(f\"{score_files_dir}/{dpl}/*/*.csv\")\n",
    "audio_files = glob(f\"{audio_dir}/{dpl}/*/*.wav\")\n",
    "save_dir = f\"{save_dir}/{dpl}\"\n",
    "Path(save_dir).mkdir(exist_ok=True)\n",
    "len(audio_files), len(score_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: \n",
    "audio folders have a few small files (1-10Mb) that seem to be trials and then 160Mb files that seem to be the real deal. \n",
    "\n",
    "For SBT-3-18, for example, only one day has the full set of recordings: 29-minute recordings starting on the half hour from 05:00 to 08:30\n",
    "\n",
    "There are 4 short files at other miscellaneous times.\n",
    "\n",
    "We should probably only use the longer, scheduled recordings. I'm guessing the others won't line up with recordings across the arry and were not meant to be used as data. \n",
    "\n",
    "Some grids have >1 day: e.g. SBT-6-83 has 5 days of complete recording schedule. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregate score dfs into sparse detection df\n",
    "- Threshold detections\n",
    "- make sparse df\n",
    "- concatenate across all cards in the grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -1  # Species detection threshold\n",
    "\n",
    "# remove some non-species classes from HawkEars\n",
    "classes_to_skip = [\n",
    "    \"Noise\",\n",
    "    \"Mashup\",\n",
    "    \"Other\",\n",
    "]\n",
    "#'Philadelphia Vireo','Lazuli Bunting',\"Bewick's Wren\",\"MacGillivray's Warbler\",\"Squirrel\",\"Purple Finch\", \"Canine\", \"Noise\", \"Other\", \"Gray Treefrog\", 'Spring Peeper', 'American Goshawk', 'Pacific-slope Flycatcher', 'Mashup', 'Rooster', 'Black-crowned Night Heron']\n",
    "\n",
    "Path(save_dir).mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def make_spars_df(path):\n",
    "    d = pd.read_csv(path, index_col=[0, 1, 2])\n",
    "    d = d.drop(columns=classes_to_skip)\n",
    "    sp_arr = csr_matrix(d > threshold)\n",
    "    return pd.DataFrame.sparse.from_spmatrix(sp_arr, index=d.index, columns=d.columns)\n",
    "\n",
    "\n",
    "sparse_detection_dfs = [make_spars_df(path) for path in score_files]\n",
    "detections = pd.concat(sparse_detection_dfs)\n",
    "# detections.to_pickle('./sparse_detections_grid1.pkl')\n",
    "# reloaded = pd.read_pickle('./sparse_detections_grid1.pkl')\n",
    "# reloaded.shape\n",
    "# (detections.astype(int).sum(0) == reloaded.astype(int).sum(0)).all()\n",
    "\n",
    "# can skip rows with no classes detected\n",
    "filtered = detections[detections.astype(bool).sum(1) > 0]\n",
    "dest = save_dir + f\"dets_{dpl}_thresh{threshold}.pkl\"\n",
    "filtered.to_pickle(dest)\n",
    "print(f\"saved pickled dets to {dest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpl_cnts = filtered.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Red-eyed Vireo                  481445\n",
       "White-throated Sparrow           80963\n",
       "Ovenbird                         68431\n",
       "Winter Wren                      45076\n",
       "Yellow-rumped Warbler            44519\n",
       "American Robin                   26629\n",
       "Western Tanager                  20836\n",
       "Black-throated Green Warbler     12854\n",
       "Mourning Warbler                 11296\n",
       "Blue-headed Vireo                10967\n",
       "Rose-breasted Grosbeak           10738\n",
       "Swainson's Thrush                10576\n",
       "Purple Finch                      9764\n",
       "Squirrel                          9697\n",
       "Harris's Sparrow                  8536\n",
       "Philadelphia Vireo                7584\n",
       "Hermit Thrush                     6554\n",
       "Mountain Chickadee                6182\n",
       "Canada Warbler                    6153\n",
       "Townsend's Solitaire              5341\n",
       "dtype: Sparse[int64, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpl_cnts[dpl_cnts > 0].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repeat for all arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dpl = [Path(f).name for f in glob(f\"{score_files_dir}/*\")]\n",
    "for dpl in all_dpl:\n",
    "    score_files = glob(f\"{score_files_dir}/{dpl}/*/*.csv\")\n",
    "    save_path = f\"{save_dir}/{dpl}\"\n",
    "    Path(save_path).mkdir(exist_ok=True)\n",
    "\n",
    "    sparse_detection_dfs = [make_spars_df(path) for path in score_files]\n",
    "    if len(sparse_detection_dfs) > 0:\n",
    "        detections = pd.concat(sparse_detection_dfs)\n",
    "\n",
    "        # can skip rows with no classes detected\n",
    "        filtered = detections[detections.astype(bool).sum(1) > 0]\n",
    "        dest = f\"{save_path}/dets_{dpl}_thresh{threshold}.pkl\"\n",
    "        filtered.to_pickle(dest)\n",
    "        print(f\"saved pickled dets to {dest}\")\n",
    "    else:\n",
    "        print(f\"no dets for {dpl}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opso0110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
